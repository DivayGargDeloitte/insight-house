{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c9e096-a5b1-42a5-8ac0-e00d6ecb9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b3c9e3-cdb6-4ff8-89ba-e06c8f6a1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bucket_name =\"lifesight-data-table/MLops\"\n",
    "Bucket_uri = \"gs://lifesight-data-table/MLops\"\n",
    "data_path = Bucket_uri+\"/\"+\"data/house_data.csv\"\n",
    "processed_train = Bucket_uri+\"/\"+\"train/train_data.csv\"\n",
    "processed_test = Bucket_uri+\"/\"+\"test/test_data.csv\"\n",
    "model_path = Bucket_uri+\"/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123dc781-b454-4c81-87c0-6f67be1b0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(config.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfda0eb-e993-41a7-9499-978965486339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(['id','date'],axis=1,inplace=True)\n",
    "#converting built year to actual age of the house\n",
    "data['built_age'] = 2021 - data.yr_built \n",
    "data.drop('yr_built',axis=1,inplace=True)\n",
    "\n",
    "X = list(data.iloc[:,1:].values) #independent\n",
    "y = data.price.values #dependent\n",
    "#scaling X values\n",
    "sn = StandardScaler()\n",
    "X = sn.fit_transform(X)\n",
    "\n",
    "y = np.log10(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train['y_train'] = y_train\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test['y_test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bca3abc-38e9-4446-8581-48ff4efe4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(config.processed_train,index=False)\n",
    "X_test.to_csv(config.processed_test,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15a101-95ba-41e0-bdd5-c6e8da85462b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10ee5d3-b1fd-4ef8-99e8-e800c42cdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c6c8fb-b240-4ce0-9dbb-d8515d5926f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(config.processed_train)\n",
    "y_train = train_data['y_train']\n",
    "X_train = train_data.drop(columns=['y_train'])\n",
    "\n",
    "lr = LinearRegression(normalize=True,fit_intercept=True,n_jobs=1)\n",
    "lr.fit(X_train,y_train)\n",
    "filename = 'model.sav'\n",
    "pickle.dump(lr,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3782a367-5e63-4603-89f8-5edc018e4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.Client().bucket(config.gs_bucket_name)\n",
    "blob = bucket.blob(str('MLops/model/')+filename)\n",
    "blob.upload_from_filename(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95838f1d-8112-44fc-9a3c-691361304538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e578283-0445-479f-b40f-a8c0be2a3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#import os\n",
    "import pickle\n",
    "from tempfile import TemporaryFile\n",
    "from google.cloud import storage\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97affaa-541c-4483-bdd6-9ec2e14364a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(config.processed_test)\n",
    "y_test = test_data['y_test']\n",
    "X_test = test_data.drop(columns=['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff6c668-67a7-4e24-984d-a21b4bb5fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bucket = 'MLops/model/model.sav'\n",
    "#bucket = storage.Client().get_bucket(bucket_name)\n",
    "bucket = storage.Client().get_bucket(config.gs_bucket_name)\n",
    "blob = bucket.blob(model_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1bd848-aed5-4ed0-a35c-3747ca7c0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with TemporaryFile() as temp_file:\n",
    "    #download blob into temp file\n",
    "    blob.download_to_file(temp_file)\n",
    "    temp_file.seek(0)\n",
    "    #load into joblib\n",
    "    #model=joblib.load(temp_file)\n",
    "    loaded_model = pickle.load(temp_file)\n",
    "\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b4fbf0-b01e-4f90-923d-ad6fd38f2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['y_pred'] = y_pred\n",
    "#test_data.to_csv(\"gs://lifesight-data-table/MLops/predicted_data.csv\",index=False)\n",
    "test_data.to_csv(config.predicted_data,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050e1e0-7cbc-4a58-b308-cf7cf6ee6626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
